{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd4f609-3d23-4bbc-bbdb-aceb16e9dd52",
   "metadata": {},
   "source": [
    "# Homework 1: SAE Lens & GitHub Commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bca00-dd2e-4fc1-86ac-8827b784655d",
   "metadata": {},
   "source": [
    "[GitHub Link](https://github.com/decoderesearch/SAELens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46b0bb-5766-461c-805c-69f6bd914d9d",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7683fe-ff79-4146-88de-2464d59898f4",
   "metadata": {},
   "source": [
    "* [About SAE Lens](#bullet1)\n",
    "* [Plots](#bullet2)\n",
    "* [Commit Question](#bullet3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c052b64-8f4f-4c1e-8e72-bcd6a4d8e103",
   "metadata": {},
   "source": [
    "## About SAE Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04caf384-3a6b-4634-873e-57ed7d1d02f4",
   "metadata": {},
   "source": [
    "SAE Lens is a **Python library** for using _pretrained sparse autoencoders_ (SAEs) or _training_ your own to analyze Large Language Model (LLM) features.\n",
    "\n",
    "They work by encoding a concept that an LLM may take as input or output and _approximating it with the minimum number of neurons possible_. This allows researchers to discover **which neurons** in an LLM neural network layer convey **which concepts**.\n",
    "\n",
    "I have personally used SAE Lens in an independent project where I discovered the primary \"axis\" of concepts encoded by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469467d2-02ce-4939-8e54-161557e49571",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759d582-4f68-4047-96c8-f0912f545b0e",
   "metadata": {},
   "source": [
    "Below is a series of plots from the public SAE Lens repository, illustrating the training loss of a SAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7e06d-74c1-4515-9b3e-46e11b99bcf3",
   "metadata": {},
   "source": [
    "![SAE Training Plots](dashboard_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0a95b-267a-4409-a3b9-77600449e2b5",
   "metadata": {},
   "source": [
    "# Commit Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2a030-d98a-46dc-8992-c58ac04b522b",
   "metadata": {},
   "source": [
    "I viewed the history of the git commits using `git log -p`. In doing so, I could view the actual code changes in each file. The changes in the `HW 1 - Practicing Commits.py` file look very simple, new lines with plain python code. On the other hand, the changes in the `HW1.ipynb` file look a lot more complicated, with unfamiliar code defining each cell and the format of each cell. My presumption is that the Jupyter Notebook is actually based on a different programming language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
